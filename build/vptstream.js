!function(e,t){"object"==typeof exports&&"object"==typeof module?module.exports=t():"function"==typeof define&&define.amd?define([],t):"object"==typeof exports?exports.VPTStream=t():e.VPTStream=t()}(self,(function(){return e={807:e=>{e.exports="uniform sampler2D map;\nuniform float opacity;\nuniform float width;\nuniform float height;\nuniform float depthMin;\nuniform float depthMax;\nuniform vec3 thresholdMin;\nuniform vec3 thresholdMax;\n\nvarying vec2 vUv;\n\n#define BRIGHTNESS_THRESHOLD_OFFSET 0.01\n#define FLOAT_EPS 0.00001\n\nconst float _DepthSaturationThreshhold = 0.3; //a given pixel whose saturation is less than half will be culled (old default was .5)\nconst float _DepthBrightnessThreshold = 0.4; //a given pixel whose brightness is less than half will be culled (old default was .9)\n\nvec3 rgb2hsv(vec3 c)\n{\n  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n  float d = q.x - min(q.w, q.y);\n  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + FLOAT_EPS)), d / (q.x + FLOAT_EPS), q.x);\n}\n\nvoid main() {\n\n  float verticalScale = 0.5;//480.0 / 720.0;\n  float verticalOffset = 1.0 - verticalScale;\n\n  vec2 colorUv = vUv * vec2(1.0, verticalScale) + vec2(0.0, 0.5);\n  vec2 depthUv = colorUv - vec2(0.0, 0.5);\n\n  vec4 colorSample = texture2D(map, colorUv); \n  vec4 depthSample = texture2D(map, depthUv); \n\n  vec3 hsv = rgb2hsv(depthSample.rgb);\n  float depth = hsv.b > _DepthBrightnessThreshold + BRIGHTNESS_THRESHOLD_OFFSET ? hsv.r : 0.0;\n  float z = depth * (depthMax - depthMin) + depthMin;\n  float alpha = depth > 0.0 && z > thresholdMin.z && z < thresholdMax.z ? 1.0 : 0.0;\n\n  if(alpha <= 0.0) {\n    discard;\n  }\n\n  colorSample.a *= (alpha * opacity);\n\n  gl_FragColor = colorSample;\n}"},206:e=>{e.exports="varying vec2 vUv;\nuniform float pointSize;\nuniform float depthMin;\nuniform float depthMax;\nuniform float scale;\nuniform vec3 thresholdMin;\nuniform vec3 thresholdMax;\n\nvoid main()\n{\n  vUv = uv;\n  gl_Position =  projectionMatrix * modelViewMatrix * vec4(position,1.0);\n}"},683:e=>{e.exports="uniform sampler2D map;\nuniform float opacity;\nuniform float width;\nuniform float height;\nuniform float depthMin;\nuniform float depthMax;\nuniform vec3 thresholdMin;\nuniform vec3 thresholdMax;\n\nvarying vec4 ptColor;\nvarying vec2 vUv;\nvarying vec3 debug;\n\n#define BRIGHTNESS_THRESHOLD_OFFSET 0.01\n#define FLOAT_EPS 0.00001\n\nconst float _DepthSaturationThreshhold = 0.3; //a given pixel whose saturation is less than half will be culled (old default was .5)\nconst float _DepthBrightnessThreshold = 0.6; //a given pixel whose brightness is less than half will be culled (old default was .9)\n\nvec3 rgb2hsv(vec3 c)\n{\n    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n    vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n    vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n    float d = q.x - min(q.w, q.y);\n    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + FLOAT_EPS)), d / (q.x + FLOAT_EPS), q.x);\n}\n\nfloat depthForPoint(vec2 texturePoint)\n{\n    vec4 depthsample = texture2D(map, texturePoint);\n    vec3 depthsamplehsv = rgb2hsv(depthsample.rgb);\n    return depthsamplehsv.g > _DepthSaturationThreshhold && depthsamplehsv.b > _DepthBrightnessThreshold ? depthsamplehsv.r : 0.0;\n}\n\nvoid main() {\n\n  /*float verticalScale = 480.0 / 720.0;\n  float verticalOffset = 1.0 - verticalScale;\n  vec2 colorUv = vUv * vec2(0.5, verticalScale) + vec2(0, verticalOffset);\n  vec2 depthUv = colorUv + vec2(0.5, 0.0);*/\n\n\n    float verticalScale = 0.5;//480.0 / 720.0;\n    float verticalOffset = 1.0 - verticalScale;\n\n    vec2 colorUv = vUv * vec2(1.0, verticalScale) + vec2(0.0, 0.5);\n    vec2 depthUv = colorUv - vec2(0.0, 0.5);\n\n    vec4 colorSample = ptColor;// texture2D(map, colorUv); \n    vec4 depthSample = texture2D(map, depthUv); \n\n    vec3 hsv = rgb2hsv(depthSample.rgb);\n    float depth = hsv.b > _DepthBrightnessThreshold + BRIGHTNESS_THRESHOLD_OFFSET ? hsv.r : 0.0;\n    float z = depth * (depthMax - depthMin) + depthMin;\n    float alpha = depth > 0.0 && z > thresholdMin.z && z < thresholdMax.z ? 1.0 : 0.0;\n\n    if(alpha <= 0.0) {\n      discard;\n    }\n\n    colorSample.a *= (alpha * opacity);\n\n    gl_FragColor = colorSample;//vec4(debug, 1);\n}"},60:e=>{e.exports="uniform sampler2D map;\n\nuniform float pointSize;\nuniform float depthMin;\nuniform float depthMax;\nuniform vec3 thresholdMin;\nuniform vec3 thresholdMax;\nuniform float scale;\nvarying vec4 ptColor;\nvarying vec2 vUv;\nvarying vec3 debug;\n\nconst float _DepthSaturationThreshhold = 0.3; //a given pixel whose saturation is less than half will be culled (old default was .5)\nconst float _DepthBrightnessThreshold = 0.3; //a given pixel whose brightness is less than half will be culled (old default was .9)\nconst float  _Epsilon = .03;\n\n//https://github.com/tobspr/GLSL-Color-Spaces/blob/master/ColorSpaces.inc.glsl\nconst float SRGB_GAMMA = 1.0 / 2.2;\nconst float SRGB_INVERSE_GAMMA = 2.2;\nconst float SRGB_ALPHA = 0.055;\n\n// Converts a single srgb channel to rgb\nfloat srgb_to_linear(float channel) {\n  if (channel <= 0.04045)\n      return channel / 12.92;\n  else\n      return pow((channel + SRGB_ALPHA) / (1.0 + SRGB_ALPHA), 2.4);\n}\n\n// Converts a srgb color to a linear rgb color (exact, not approximated)\nvec3 srgb_to_rgb(vec3 srgb) {\n  return vec3(\n      srgb_to_linear(srgb.r),\n      srgb_to_linear(srgb.g),\n      srgb_to_linear(srgb.b)\n  );\n}\n\n//faster but noisier\nvec3 srgb_to_rgb_approx(vec3 srgb) {\nreturn pow(srgb, vec3(SRGB_INVERSE_GAMMA));\n}\n\nvec3 rgb2hsv(vec3 c)\n{\n  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n\n  float d = q.x - min(q.w, q.y);\n  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + _Epsilon)), d / (q.x + _Epsilon), q.x);\n}\n\n\nfloat depthForPoint(vec2 texturePoint)\n{\n  vec4 depthsample = texture2D(map, texturePoint);\n  vec3 linear = srgb_to_rgb( depthsample.rgb);\n  vec3 depthsamplehsv = rgb2hsv(linear.rgb);\n  return depthsamplehsv.g > _DepthSaturationThreshhold && depthsamplehsv.b > _DepthBrightnessThreshold ? depthsamplehsv.r : 0.0;\n}\n\nvoid main()\n{\n  float mindepth = depthMin;\n  float maxdepth = depthMax;\n\n  float verticalScale = 0.5;//480.0 / 720.0;\n  float verticalOffset = 1.0 - verticalScale;\n\n  vec2 colorUv = uv * vec2(1.0, verticalScale) + vec2(0.0, 0.5);\n  vec2 depthUv = colorUv - vec2(0.0, 0.5);\n\n  float depth = depthForPoint(depthUv);\n\n  float z = depth * (maxdepth - mindepth) + mindepth;\n  \n  vec4 worldPos = vec4(position.xy, -z, 1.0);\n  worldPos.w = 1.0;\n\n  vec4 mvPosition = vec4( worldPos.xyz, 1.0 );\n  mvPosition = modelViewMatrix * mvPosition;\n\n  ptColor = texture2D(map, colorUv);\n\n  gl_Position = projectionMatrix * modelViewMatrix * worldPos;\n  vUv = uv;\n  debug = vec3(1, 0.5, 0.0);\n  \n  gl_PointSize = pointSize;\n  gl_PointSize *= ( scale / - mvPosition.z );\n\n  //gl_Position =  projectionMatrix * modelViewMatrix * vec4(position,1.0);\n}"},104:e=>{e.exports="\nuniform sampler2D map;\nuniform float opacity;\nuniform float width;\nuniform float height;\n\nvarying vec4 ptColor;\nvarying vec2 vUv;\nvarying vec3 debug;\n\nvoid main() {\n\n    if( ptColor.a <= 0.0){\n        discard;\n    }\n\n    vec4 colorSample = ptColor;\n    colorSample.a *= (ptColor.a * opacity);\n\n    gl_FragColor = colorSample;\n}"},961:e=>{e.exports="\nuniform vec2 focalLength;//fx,fy\nuniform vec2 principalPoint;//ppx,ppy\nuniform vec2 imageDimensions;\nuniform mat4 extrinsics;\nuniform float width;\nuniform float height;\nuniform float scale;\nuniform sampler2D map;\n\nuniform float pointSize;\nuniform float depthMin;\nuniform float depthMax;\nuniform vec3 thresholdMin;\nuniform vec3 thresholdMax;\nvarying vec4 ptColor;\nvarying vec2 vUv;\nvarying vec3 debug;\n\nconst float _DepthSaturationThreshhold = 0.3; //a given pixel whose saturation is less than half will be culled (old default was .5)\nconst float _DepthBrightnessThreshold = 0.3; //a given pixel whose brightness is less than half will be culled (old default was .9)\nconst float  _Epsilon = .03;\n\n#define BRIGHTNESS_THRESHOLD_OFFSET 0.01\n#define FLOAT_EPS 0.00001\n#define CLIP_EPSILON 0.005\n\nvec3 rgb2hsv(vec3 c)\n{\n    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n    vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n    vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n    float d = q.x - min(q.w, q.y);\n    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + FLOAT_EPS)), d / (q.x + FLOAT_EPS), q.x);\n}\n\nfloat depthForPoint(vec2 texturePoint)\n{       \n    vec2 centerpix = vec2(1.0/width, 1.0/height) * 0.5;\n    texturePoint += centerpix;\n\n    // clamp to texture bounds - 0.5 pixelsize so we do not sample outside our texture\n    texturePoint = clamp(texturePoint, centerpix, vec2(1.0, 0.5) - centerpix);\n    vec4 depthsample = texture2D(map, texturePoint);\n    vec3 depthsamplehsv = rgb2hsv(depthsample.rgb);\n    return depthsamplehsv.b > _DepthBrightnessThreshold + BRIGHTNESS_THRESHOLD_OFFSET ? depthsamplehsv.r : 0.0;\n}\n\n//https://stackoverflow.com/questions/12751080/glsl-point-inside-box-test/37426532\nfloat insideBox3D(vec3 v, vec3 bottomLeft, vec3 topRight) {\n    vec3 s = step(bottomLeft, v) - step(topRight, v);\n    return s.x * s.y * s.z; \n}\n\nvoid main()\n{   \n    vec4 texSize = vec4(1.0 / width, 1.0 / height, width, height);\n    vec2 basetex = position.xy + vec2(0.5,0.5);\n\n    // we align our depth pixel centers with the center of each quad, so we do not require a half pixel offset\n    vec2 depthTexCoord = basetex * vec2(1.0, 0.5);\n    vec2 colorTexCoord = basetex * vec2(1.0, 0.5) + vec2(0.0, 0.5);\n\n    float depth = depthForPoint(depthTexCoord);\n    float mindepth = depthMin;\n    float maxdepth = depthMax;\n\n    float z = depth * (maxdepth - mindepth) + mindepth;\n    vec2 ortho = basetex * imageDimensions - principalPoint;\n    vec2 proj = ortho * z / focalLength;\n    vec4 worldPos = extrinsics *  vec4(proj.xy, z, 1.0);\n    worldPos.w = 1.0;\n\n    vec4 mvPosition = vec4( worldPos.xyz, 1.0 );\n    mvPosition = modelViewMatrix * mvPosition;\n    ptColor = texture2D(map, colorTexCoord);\n\n    ptColor.a = insideBox3D(worldPos.xyz, thresholdMin, thresholdMax ) > 0.0 && depth > 0.0 ? 1.0 : 0.0;\n\n    mat4 flip = mat4(  vec4(-1.0,0.0,0.0,0.0),\n                        vec4(0.0,1.0,0.0,0.0),\n                        vec4(0.0,0.0,1.0,0.0),\n                        vec4(0.0,0.0,0.0,1.0));\n    \n    gl_Position = projectionMatrix * modelViewMatrix * flip * worldPos;\n    vUv = uv;\n    debug = vec3(1, 0.5, 0.0);\n\n    gl_PointSize = pointSize;\n    gl_PointSize *= ( scale / - mvPosition.z );\n\n}\n"},979:(e,t,n)=>{const i=n(104),a=n(961),s=n(683),o=n(60),r=n(807),l=n(206),h={videoPath:{type:"string"},meta:{type:"object",defaults:{}},startat:{type:"number",default:0},renderMode:{type:"string",default:"perspective"},depthMin:{type:"number",default:.29},depthMax:{type:"number",default:4},pointSize:{type:"number",default:8},scale:{type:"number",default:1},textureSize:{type:"vec2",default:{w:320,h:240}},thresholdMin:{type:"vec3",default:{x:-2,y:-2,z:0}},thresholdMax:{type:"vec3",default:{x:2,y:2,z:4}}},p=Object.freeze({PLAY_SUCCESS:"PLAY_SUCCESS",PLAY_ERROR:"PLAY_ERROR",LOAD_ERROR:"LOAD_ERROR",NETWORK_ERROR:"NETWORK_ERROR",MEDIA_ERROR:"MEDIA_ERROR",HLS_ERROR:"HLS_ERROR"});class c extends THREE.Object3D{constructor(){super(),this.video=this.createVideoEl(),this.texture=new THREE.VideoTexture(this.video),this.texture.minFilter=THREE.NearestFilter,this.texture.magFilter=THREE.LinearFilter,this.texture.format=THREE.RGBFormat,this.hls=null,this.hls_xhroverride=null,this.loadTime=0,this.playing=!1,this.meshScalar=2,this.params={}}static get STREAMEVENTS(){return p}get LoadTime(){return this.loadTime}get Playing(){return this.playing}updateParameter(e,t){"startat"==e?this.video.currentTime=t:this.material&&(this.material.uniforms[e].value=t)}load(e){console.log("vptstream load");for(const t in h)console.log(`${t} value:${e[t]} default:${h[t].default}`),this.params[t]=e.hasOwnProperty(t)?e[t]:h[t].default;this.params.meta.hasOwnProperty("depthFocalLength")?this.setProps(this.params.meta):(console.error("invalid meta data for perspective rendering, default to cutout"),this.params.renderMode="cutout");const t=new THREE.Matrix4,n=this.props.extrinsics;if(t.set(n.e00,n.e10,n.e20,n.e30,n.e01,n.e11,n.e21,n.e31,n.e02,n.e12,n.e22,n.e32,n.e03,n.e13,n.e23,n.e33),this.material){console.log("Material exists, dispose"),this.material.dispose();const e=this.getObjectByName("VolumetricVideo");e&&(console.log("VolumetricVideo exists, remove"),this.remove(e))}this.startVideo(this.params.videoPath);let p=new THREE.PlaneBufferGeometry(1,1,this.params.textureSize.w,this.params.textureSize.h);switch(this.params.renderMode){case"ortho":this.material=new THREE.ShaderMaterial({uniforms:{map:{type:"t",value:this.texture},time:{type:"f",value:0},opacity:{type:"f",value:1},pointSize:{type:"f",value:this.params.pointSize},depthMin:{type:"f",value:this.params.depthMin},depthMax:{type:"f",value:this.params.depthMax},thresholdMin:{value:this.params.thresholdMin},thresholdMax:{value:this.params.thresholdMax},scale:{value:this.params.scale},extensions:{derivatives:!0}},side:THREE.DoubleSide,vertexShader:o,fragmentShader:s,transparent:!0});let e=new THREE.Points(p,this.material);e.position.y=1,e.name="VolumetricVideo",this.add(e);break;case"cutout":this.material=new THREE.ShaderMaterial({uniforms:{map:{type:"t",value:this.texture},time:{type:"f",value:0},opacity:{type:"f",value:1},depthMin:{type:"f",value:this.params.depthMin},depthMax:{type:"f",value:this.params.depthMax},thresholdMin:{value:this.params.thresholdMin},thresholdMax:{value:this.params.thresholdMax},scale:{value:this.params.scale},extensions:{derivatives:!0}},side:THREE.DoubleSide,vertexShader:l,fragmentShader:r,transparent:!0});let n=new THREE.Mesh(p,this.material);n.position.y=1,n.scale.set(this.params.textureSize.w/this.params.textureSize.h,1,1),n.name="VolumetricVideo",this.add(n);break;case"perspective":this.material=new THREE.ShaderMaterial({uniforms:{map:{type:"t",value:this.texture},pointSize:{type:"f",value:this.params.pointSize},depthMin:{type:"f",value:this.params.depthMin},depthMax:{type:"f",value:this.params.depthMax},scale:{value:this.params.scale},focalLength:{value:this.props.depthFocalLength},principalPoint:{value:this.props.depthPrincipalPoint},imageDimensions:{value:this.props.depthImageSize},width:{value:this.props.textureWidth},height:{value:this.props.textureHeight},thresholdMin:{value:this.params.thresholdMin},thresholdMax:{value:this.params.thresholdMax},extrinsics:{value:t},opacity:{type:"f",value:1}},extensions:{derivatives:!0},vertexShader:a,fragmentShader:i,transparent:!0}),this.material.side=THREE.DoubleSide;let h=new THREE.Points(p,this.material);h.name="VolumetricVideo",h.position.y=1,this.add(h);break;case"perspective_rl2":this.material=new THREE.ShaderMaterial({uniforms:{map:{type:"t",value:this.texture},pointSize:{type:"f",value:this.params.pointSize},depthMin:{type:"f",value:this.params.depthMin},depthMax:{type:"f",value:this.params.depthMax},scale:{value:this.params.scale},focalLength:{value:this.props.depthFocalLength},principalPoint:{value:this.props.depthPrincipalPoint},imageDimensions:{value:this.props.depthImageSize},width:{value:this.props.textureWidth},height:{value:this.props.textureHeight},thresholdMin:{value:this.params.thresholdMin},thresholdMax:{value:this.params.thresholdMax},extrinsics:{value:t},opacity:{type:"f",value:1}},extensions:{derivatives:!0},vertexShader:rgbdVert_rs2,fragmentShader:rgbdFrag_rs2,transparent:!0}),this.material.side=THREE.DoubleSide;let c=new THREE.Points(p,this.material);c.name="VolumetricVideo",c.position.y=1,this.add(c)}}loadPropsFromFile(e){return new Promise(((t,n)=>{const i=new THREE.FileLoader(this.manager);i.setResponseType("json"),i.load(e,(e=>{t(e)}),null,(e=>{n(e)}))}))}setProps(e){this.props=e,null!=this.props.textureWidth&&null!=this.props.textureHeight||(this.props.textureWidth=this.props.depthImageSize.x,this.props.textureHeight=2*this.props.depthImageSize.y),null==this.props.extrinsics&&(this.props.extrinsics={e00:1,e01:0,e02:0,e03:0,e10:0,e11:1,e12:0,e13:0,e20:0,e21:0,e22:1,e23:0,e30:0,e31:0,e32:0,e33:1}),null==this.props.crop&&(this.props.crop={x:0,y:0,z:1,w:1})}play(){return this.video.play().then((function(){this.dispatchEvent({type:p.PLAY_SUCCESS,message:"autoplay success"}),this.playing=!0})).catch((function(e){this.dispatchEvent({type:p.PLAY_ERROR,message:"autoplay error"}),this.playing=!1})),this.playing}stop(){this.video.stop()}pause(){}setVolume(e){this.video.volume=e}update(e){this._material.uniforms.time.value=e}createVideoEl(){const e=document.createElement("video");return e.setAttribute("id","volumetric-stream-video"),e.setAttribute("playsinline",""),e.setAttribute("webkit-playsinline",""),e.autoplay=!0,e.muted=!1,e.preload="auto",e.crossOrigin="anonymous",console.log("Volumetric Stream: Video element created",e),e}scaleToAspectRatio(e,t){const n=Math.min(1,1/t),i=Math.min(1,t);e.object3DMap.mesh.scale.set(n,i,1),e.object3DMap.mesh.matrixNeedsUpdate=!0}dispose(){if(this.texture.image instanceof HTMLVideoElement){const e=this.texture.image;e.pause(),e.src="",e.load()}this.hls&&(this.hls.stopLoad(),this.hls.detachMedia(),this.hls.destroy(),this.hls=null),this.texture.dispose(),this.material.dispose()}setVideoUrl(e){this.hls&&this.startVideo(e)}startVideo(e){console.log("startVideo "+e),Hls.isSupported()?(()=>{this.hls&&(this.hls.stopLoad(),this.hls.detachMedia(),this.hls.destroy(),this.hls=null),this.hls_xhroverride?this.hls=new Hls({xhrSetup:this.hls_xhroverride}):this.hls=new Hls,this.hls.loadSource(e),this.hls.attachMedia(this.video),this.hls.on(Hls.Events.ERROR,((e,t)=>{if(t.fatal)switch(t.type){case Hls.ErrorTypes.NETWORK_ERROR:this.dispatchEvent({type:p.NETWORK_ERROR,message:t.message}),this.hls.startLoad();break;case Hls.ErrorTypes.MEDIA_ERROR:this.dispatchEvent({type:p.MEDIA_ERROR,message:t.message}),this.hls.recoverMediaError();break;default:return void this.dispatchEvent({type:p.HLS_ERROR,message:`hls error ${t.type} ${t.message}`})}else console.log("Hls non fatar error:",t),t.type,Hls.ErrorTypes.MEDIA_ERROR})),this.hls.on(Hls.Events.MANIFEST_PARSED,((e,t)=>{this.loadTime=performance.now();const n=this;this.video.play().then((function(){console.log("Hls success auto playing "+n.params.startat),n.video.currentTime=n.params.startat,n.dispatchEvent({type:p.PLAY_SUCCESS,message:"autoplay success"}),n.playing=!0})).catch((function(e){n.dispatchEvent({type:p.PLAY_ERROR,message:"error trying to auto play "+e+" "+e.name}),n.playing=!1}))}))})():this.video.canPlayType(contentType)?(this.video.src=e,this.video.onerror=failLoad,this.video.play().then((function(){this.dispatchEvent({type:p.PLAY_SUCCESS,message:"autoplay success"})})).catch((function(e){this.dispatchEvent({type:p.PLAY_ERROR,message:"autoplay error"}),console.log("error autoplay",data)}))):(console.log("Hls unsupported, can't load or play"),this.dispatchEvent({type:p.LOAD_ERROR,message:"Hls unsupported, can't play media"}))}}e.exports=c}},t={},function n(i){var a=t[i];if(void 0!==a)return a.exports;var s=t[i]={exports:{}};return e[i](s,s.exports,n),s.exports}(979);var e,t}));
//# sourceMappingURL=vptstream.js.map